{
 "metadata": {
  "name": "",
  "signature": "sha256:b79c92dd20992bc7c285e2060a084d5600975ce108fcee1f1b5cb383a1d63b98"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import pandas\n",
      "import math\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_clss = pandas.read_csv(u'C:\\\\Users\\\\Dmi\\\\Desktop\\\\MatLab\\\\Coursera\\\\\u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0432 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\\\\\u041d\u0435\u0434\u0435\u043b\u044f 3\\\\\u0427\u0430\u0441\u0442\u044c 3\\\\classification.csv',\n",
      "                     header = 0)\n",
      "df_scores = pandas.read_csv(u'C:\\\\Users\\\\Dmi\\\\Desktop\\\\MatLab\\\\Coursera\\\\\u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0432 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\\\\\u041d\u0435\u0434\u0435\u043b\u044f 3\\\\\u0427\u0430\u0441\u0442\u044c 3\\\\scores.csv',\n",
      "                     header = 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df_clss.head()\n",
      "print df_scores.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   true  pred\n",
        "0     1     0\n",
        "1     1     1\n",
        "2     1     1\n",
        "3     0     0\n",
        "4     1     1\n",
        "   true  score_logreg  score_svm  score_knn  score_tree\n",
        "0     0      0.683832   0.145976   0.787063    0.500000\n",
        "1     1      0.801966   0.239511   1.000000    0.833333\n",
        "2     0      0.382315  -0.245701   0.000000    0.000000\n",
        "3     1      0.506797  -0.137058   0.000000    0.105263\n",
        "4     1      0.488781  -0.154148   0.000000    0.105263\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(df_clss[df_clss['true']  == 1][df_clss['pred'] == 1])\n",
      "print len(df_clss[df_clss['true']  == 0][df_clss['pred'] == 1])\n",
      "print len(df_clss[df_clss['true']  == 1][df_clss['pred'] == 0])\n",
      "print len(df_clss[df_clss['true']  == 0][df_clss['pred'] == 0])\n",
      "print confusion_matrix(df_clss['true'], df_clss['pred'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "43\n",
        "34\n",
        "59\n",
        "64\n",
        "[[64 34]\n",
        " [59 43]]\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print round(accuracy_score(df_clss['true'], df_clss['pred']), 2)\n",
      "print round(precision_score(df_clss['true'], df_clss['pred']), 2)\n",
      "print round(recall_score(df_clss['true'], df_clss['pred']), 2)\n",
      "print round(f1_score(df_clss['true'], df_clss['pred']), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.54\n",
        "0.56\n",
        "0.42\n",
        "0.48\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print round(roc_auc_score(df_scores['true'], df_scores['score_logreg']), 2)\n",
      "print round(roc_auc_score(df_scores['true'], df_scores['score_svm']), 2)\n",
      "print round(roc_auc_score(df_scores['true'], df_scores['score_knn']), 2)\n",
      "print round(roc_auc_score(df_scores['true'], df_scores['score_tree']), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.72\n",
        "0.71\n",
        "0.64\n",
        "0.69\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_logreg = precision_recall_curve(df_scores['true'], df_scores['score_logreg'])\n",
      "score_svm = precision_recall_curve(df_scores['true'], df_scores['score_svm'])\n",
      "score_knn = precision_recall_curve(df_scores['true'], df_scores['score_knn'])\n",
      "score_tree = precision_recall_curve(df_scores['true'], df_scores['score_tree'])\n",
      "print round(max(score_logreg[0][score_logreg[1] >= 0.7]), 2)\n",
      "print round(max(score_svm[0][score_svm[1] >= 0.7]), 2)\n",
      "print round(max(score_knn[0][score_knn[1] >= 0.7]), 2)\n",
      "print round(max(score_tree[0][score_tree[1] >= 0.7]), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.63\n",
        "0.62\n",
        "0.61\n",
        "0.65\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}