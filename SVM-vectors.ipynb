{
 "metadata": {
  "name": "",
  "signature": "sha256:30313345d17c4dc7bf00a7a137886ac84fe690d84b3b49c4c3137a07420ce778"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import pandas\n",
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pandas.read_csv(u'C:\\\\Users\\\\Dmi\\\\Desktop\\\\MatLab\\\\Coursera\\\\\u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0432 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\\\\\u041d\u0435\u0434\u0435\u043b\u044f 3\\\\\u0427\u0430\u0441\u0442\u044c 1\\\\svm-data.csv', \n",
      "                     header = None)\n",
      "print df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   0     1     2\n",
        "0  0  0.70  0.29\n",
        "1  1  0.23  0.55\n",
        "2  0  0.72  0.42\n",
        "3  0  0.98  0.68\n",
        "4  0  0.48  0.39\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = df[0]\n",
      "X = df.ix[:, 1:]\n",
      "print X.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      1     2\n",
        "0  0.70  0.29\n",
        "1  0.23  0.55\n",
        "2  0.72  0.42\n",
        "3  0.98  0.68\n",
        "4  0.48  0.39\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC(C = 100000, kernel = 'linear', random_state = 241)\n",
      "clf.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "SVC(C=100000, cache_size=200, class_weight=None, coef0=0.0,\n",
        "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
        "  max_iter=-1, probability=False, random_state=241, shrinking=True,\n",
        "  tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(SVC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on class SVC in module sklearn.svm.classes:\n",
        "\n",
        "class SVC(sklearn.svm.base.BaseSVC)\n",
        " |  C-Support Vector Classification.\n",
        " |  \n",
        " |  The implementation is based on libsvm. The fit time complexity\n",
        " |  is more than quadratic with the number of samples which makes it hard\n",
        " |  to scale to dataset with more than a couple of 10000 samples.\n",
        " |  \n",
        " |  The multiclass support is handled according to a one-vs-one scheme.\n",
        " |  \n",
        " |  For details on the precise mathematical formulation of the provided\n",
        " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
        " |  other, see the corresponding section in the narrative documentation:\n",
        " |  :ref:`svm_kernels`.\n",
        " |  \n",
        " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
        " |  \n",
        " |  Parameters\n",
        " |  ----------\n",
        " |  C : float, optional (default=1.0)\n",
        " |      Penalty parameter C of the error term.\n",
        " |  \n",
        " |  kernel : string, optional (default='rbf')\n",
        " |       Specifies the kernel type to be used in the algorithm.\n",
        " |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
        " |       a callable.\n",
        " |       If none is given, 'rbf' will be used. If a callable is given it is\n",
        " |       used to pre-compute the kernel matrix from data matrices; that matrix\n",
        " |       should be an array of shape ``(n_samples, n_samples)``.\n",
        " |  \n",
        " |  degree : int, optional (default=3)\n",
        " |      Degree of the polynomial kernel function ('poly').\n",
        " |      Ignored by all other kernels.\n",
        " |  \n",
        " |  gamma : float, optional (default='auto')\n",
        " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
        " |      If gamma is 'auto' then 1/n_features will be used instead.\n",
        " |  \n",
        " |  coef0 : float, optional (default=0.0)\n",
        " |      Independent term in kernel function.\n",
        " |      It is only significant in 'poly' and 'sigmoid'.\n",
        " |  \n",
        " |  probability : boolean, optional (default=False)\n",
        " |      Whether to enable probability estimates. This must be enabled prior\n",
        " |      to calling `fit`, and will slow down that method.\n",
        " |  \n",
        " |  shrinking : boolean, optional (default=True)\n",
        " |      Whether to use the shrinking heuristic.\n",
        " |  \n",
        " |  tol : float, optional (default=1e-3)\n",
        " |      Tolerance for stopping criterion.\n",
        " |  \n",
        " |  cache_size : float, optional\n",
        " |      Specify the size of the kernel cache (in MB).\n",
        " |  \n",
        " |  class_weight : {dict, 'balanced'}, optional\n",
        " |      Set the parameter C of class i to class_weight[i]*C for\n",
        " |      SVC. If not given, all classes are supposed to have\n",
        " |      weight one.\n",
        " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
        " |      weights inversely proportional to class frequencies in the input data\n",
        " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
        " |  \n",
        " |  verbose : bool, default: False\n",
        " |      Enable verbose output. Note that this setting takes advantage of a\n",
        " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
        " |      properly in a multithreaded context.\n",
        " |  \n",
        " |  max_iter : int, optional (default=-1)\n",
        " |      Hard limit on iterations within solver, or -1 for no limit.\n",
        " |  \n",
        " |  decision_function_shape : 'ovo', 'ovr' or None, default=None\n",
        " |      Whether to return a one-vs-rest ('ovr') ecision function of shape\n",
        " |      (n_samples, n_classes) as all other classifiers, or the original\n",
        " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
        " |      (n_samples, n_classes * (n_classes - 1) / 2).\n",
        " |      The default of None will currently behave as 'ovo' for backward\n",
        " |      compatibility and raise a deprecation warning, but will change 'ovr'\n",
        " |      in 0.18.\n",
        " |  \n",
        " |      .. versionadded:: 0.17\n",
        " |         *decision_function_shape='ovr'* is recommended.\n",
        " |  \n",
        " |      .. versionchanged:: 0.17\n",
        " |         Deprecated *decision_function_shape='ovo' and None*.\n",
        " |  \n",
        " |  random_state : int seed, RandomState instance, or None (default)\n",
        " |      The seed of the pseudo random number generator to use when\n",
        " |      shuffling the data for probability estimation.\n",
        " |  \n",
        " |  Attributes\n",
        " |  ----------\n",
        " |  support_ : array-like, shape = [n_SV]\n",
        " |      Indices of support vectors.\n",
        " |  \n",
        " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
        " |      Support vectors.\n",
        " |  \n",
        " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
        " |      Number of support vectors for each class.\n",
        " |  \n",
        " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
        " |      Coefficients of the support vector in the decision function.\n",
        " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
        " |      The layout of the coefficients in the multiclass case is somewhat\n",
        " |      non-trivial. See the section about multi-class classification in the\n",
        " |      SVM section of the User Guide for details.\n",
        " |  \n",
        " |  coef_ : array, shape = [n_class-1, n_features]\n",
        " |      Weights assigned to the features (coefficients in the primal\n",
        " |      problem). This is only available in the case of a linear kernel.\n",
        " |  \n",
        " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
        " |      `support_vectors_`.\n",
        " |  \n",
        " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
        " |      Constants in decision function.\n",
        " |  \n",
        " |  Examples\n",
        " |  --------\n",
        " |  >>> import numpy as np\n",
        " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
        " |  >>> y = np.array([1, 1, 2, 2])\n",
        " |  >>> from sklearn.svm import SVC\n",
        " |  >>> clf = SVC()\n",
        " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
        " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
        " |      decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
        " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        " |      tol=0.001, verbose=False)\n",
        " |  >>> print(clf.predict([[-0.8, -1]]))\n",
        " |  [1]\n",
        " |  \n",
        " |  See also\n",
        " |  --------\n",
        " |  SVR\n",
        " |      Support Vector Machine for Regression implemented using libsvm.\n",
        " |  \n",
        " |  LinearSVC\n",
        " |      Scalable Linear Support Vector Machine for classification\n",
        " |      implemented using liblinear. Check the See also section of\n",
        " |      LinearSVC for more comparison element.\n",
        " |  \n",
        " |  Method resolution order:\n",
        " |      SVC\n",
        " |      sklearn.svm.base.BaseSVC\n",
        " |      abc.NewBase\n",
        " |      sklearn.svm.base.BaseLibSVM\n",
        " |      abc.NewBase\n",
        " |      sklearn.base.BaseEstimator\n",
        " |      sklearn.base.ClassifierMixin\n",
        " |      __builtin__.object\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data and other attributes defined here:\n",
        " |  \n",
        " |  __abstractmethods__ = frozenset([])\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
        " |  \n",
        " |  decision_function(self, X)\n",
        " |      Distance of the samples X to the separating hyperplane.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      X : array-like, shape (n_samples, n_features)\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
        " |          Returns the decision function of the sample for each class\n",
        " |          in the model.\n",
        " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
        " |          n_classes)\n",
        " |  \n",
        " |  predict(self, X)\n",
        " |      Perform classification on samples in X.\n",
        " |      \n",
        " |      For an one-class model, +1 or -1 is returned.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        " |          For kernel=\"precomputed\", the expected shape of X is\n",
        " |          [n_samples_test, n_samples_train]\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      y_pred : array, shape (n_samples,)\n",
        " |          Class labels for samples in X.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
        " |  \n",
        " |  predict_log_proba\n",
        " |      Compute log probabilities of possible outcomes for samples in X.\n",
        " |      \n",
        " |      The model need to have probability information computed at training\n",
        " |      time: fit with attribute `probability` set to True.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      X : array-like, shape (n_samples, n_features)\n",
        " |          For kernel=\"precomputed\", the expected shape of X is\n",
        " |          [n_samples_test, n_samples_train]\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      T : array-like, shape (n_samples, n_classes)\n",
        " |          Returns the log-probabilities of the sample for each class in\n",
        " |          the model. The columns correspond to the classes in sorted\n",
        " |          order, as they appear in the attribute `classes_`.\n",
        " |      \n",
        " |      Notes\n",
        " |      -----\n",
        " |      The probability model is created using cross validation, so\n",
        " |      the results can be slightly different than those obtained by\n",
        " |      predict. Also, it will produce meaningless results on very small\n",
        " |      datasets.\n",
        " |  \n",
        " |  predict_proba\n",
        " |      Compute probabilities of possible outcomes for samples in X.\n",
        " |      \n",
        " |      The model need to have probability information computed at training\n",
        " |      time: fit with attribute `probability` set to True.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      X : array-like, shape (n_samples, n_features)\n",
        " |          For kernel=\"precomputed\", the expected shape of X is\n",
        " |          [n_samples_test, n_samples_train]\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      T : array-like, shape (n_samples, n_classes)\n",
        " |          Returns the probability of the sample for each class in\n",
        " |          the model. The columns correspond to the classes in sorted\n",
        " |          order, as they appear in the attribute `classes_`.\n",
        " |      \n",
        " |      Notes\n",
        " |      -----\n",
        " |      The probability model is created using cross validation, so\n",
        " |      the results can be slightly different than those obtained by\n",
        " |      predict. Also, it will produce meaningless results on very small\n",
        " |      datasets.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
        " |  \n",
        " |  fit(self, X, y, sample_weight=None)\n",
        " |      Fit the SVM model according to the given training data.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
        " |          Training vectors, where n_samples is the number of samples\n",
        " |          and n_features is the number of features.\n",
        " |          For kernel=\"precomputed\", the expected shape of X is\n",
        " |          (n_samples, n_samples).\n",
        " |      \n",
        " |      y : array-like, shape (n_samples,)\n",
        " |          Target values (class labels in classification, real numbers in\n",
        " |          regression)\n",
        " |      \n",
        " |      sample_weight : array-like, shape (n_samples,)\n",
        " |          Per-sample weights. Rescale C per sample. Higher weights\n",
        " |          force the classifier to put more emphasis on these points.\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      self : object\n",
        " |          Returns self.\n",
        " |      \n",
        " |      Notes\n",
        " |      ------\n",
        " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
        " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
        " |      \n",
        " |      If X is a dense array, then the other methods will not support sparse\n",
        " |      matrices as input.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
        " |  \n",
        " |  coef_\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from sklearn.base.BaseEstimator:\n",
        " |  \n",
        " |  __repr__(self)\n",
        " |  \n",
        " |  get_params(self, deep=True)\n",
        " |      Get parameters for this estimator.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      deep: boolean, optional\n",
        " |          If True, will return the parameters for this estimator and\n",
        " |          contained subobjects that are estimators.\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      params : mapping of string to any\n",
        " |          Parameter names mapped to their values.\n",
        " |  \n",
        " |  set_params(self, **params)\n",
        " |      Set the parameters of this estimator.\n",
        " |      \n",
        " |      The method works on simple estimators as well as on nested objects\n",
        " |      (such as pipelines). The former have parameters of the form\n",
        " |      ``<component>__<parameter>`` so that it's possible to update each\n",
        " |      component of a nested object.\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      self\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
        " |  \n",
        " |  score(self, X, y, sample_weight=None)\n",
        " |      Returns the mean accuracy on the given test data and labels.\n",
        " |      \n",
        " |      In multi-label classification, this is the subset accuracy\n",
        " |      which is a harsh metric since you require for each sample that\n",
        " |      each label set be correctly predicted.\n",
        " |      \n",
        " |      Parameters\n",
        " |      ----------\n",
        " |      X : array-like, shape = (n_samples, n_features)\n",
        " |          Test samples.\n",
        " |      \n",
        " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
        " |          True labels for X.\n",
        " |      \n",
        " |      sample_weight : array-like, shape = [n_samples], optional\n",
        " |          Sample weights.\n",
        " |      \n",
        " |      Returns\n",
        " |      -------\n",
        " |      score : float\n",
        " |          Mean accuracy of self.predict(X) wrt. y.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print clf.support_ + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 4  5 10]\n"
       ]
      }
     ],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}